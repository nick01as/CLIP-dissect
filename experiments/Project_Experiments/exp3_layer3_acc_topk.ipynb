{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273bdeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/nick01as/CLIP-dissect\n",
    "!pip install --upgrade pip\n",
    "!pip install ftfy regex\n",
    "!pip install diffusers\n",
    "!pip install accelerate\n",
    "!pip install pandas\n",
    "!pip install torch==2.0\n",
    "\n",
    "import os\n",
    "home_dir = os.getcwd()\n",
    "os.chdir('CLIP-dissect')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statistics\n",
    "from itertools import permutations\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43d79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change number of workers before running cell\n",
    "!pip install -r requirements.txt\n",
    "!pip install transformers==4.28.0\n",
    "!pip install torchvision==0.15.1\n",
    "!pip install scipy\n",
    "!pip install matplotlib\n",
    "!pip install tornado==5.1.1\n",
    "import clip\n",
    "import data_utils\n",
    "import similarity\n",
    "import utils\n",
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fedab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Stable Diffusion\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(0)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fe5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_name = 'ViT-B/16'\n",
    "target_name = 'resnet50'\n",
    "target_layer = 'layer3'\n",
    "d_probe = 'broden' \n",
    "concept_set = 'data/20k.txt'\n",
    "\n",
    "batch_size = 200\n",
    "device = 'cuda'\n",
    "pool_mode = 'avg'\n",
    "\n",
    "save_dir = 'saved_activations'\n",
    "similarity_fn = similarity.soft_wpmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07477089",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_activations(clip_name = clip_name, target_name = target_name, target_layers = [target_layer],\n",
    "                       d_probe = d_probe, concept_set = concept_set, batch_size = batch_size,\n",
    "                       device = device, pool_mode=pool_mode, save_dir = save_dir)\n",
    "\n",
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                  target_layer = target_layer, d_probe = d_probe,\n",
    "                                  concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                  save_dir = save_dir)\n",
    "\n",
    "target_save_name, clip_save_name, text_save_name = save_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fce210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "os.chdir(home_dir)\n",
    "os.chdir('CLIP-dissect')\n",
    "\n",
    "with open(concept_set, 'r') as f:\n",
    "        words = f.read().split('\\n')\n",
    "\n",
    "# Vague words\n",
    "discard_set = ['design','designs','visual','visuals','item','items','object','objects','imagery','image','images','element','elements']\n",
    "        \n",
    "# Remove vague words\n",
    "def filter_word(word):\n",
    "    word = word.split()\n",
    "    new_word = \"\"\n",
    "    for w in word:\n",
    "        if w in discard_set:\n",
    "            continue\n",
    "        else:\n",
    "            new_word += w + ' '\n",
    "    if new_word[-1] == ' ':\n",
    "        new_word = new_word[:-1]\n",
    "    return new_word\n",
    "\n",
    "# Find index of word in concept set\n",
    "def get_id_for_word(word):\n",
    "    with open(concept_set, 'r') as f:\n",
    "        words = f.read().split('\\n')\n",
    "    try:\n",
    "        return words.index(word)\n",
    "    except:\n",
    "        print(\"Error: Word is not in concept set, {} found expected {}\".format(type(word), type('str')))\n",
    "\n",
    "# Get pre-generated images\n",
    "def get_images(word, images_to_pull, old_path, new_path, home_dir):\n",
    "    \n",
    "    concept_id = get_id_for_word(word)\n",
    "    \n",
    "    os.chdir(home_dir)\n",
    "    os.chdir(new_path)\n",
    "    \n",
    "    random_ids = []\n",
    "\n",
    "    # Pull random images from image set\n",
    "    while len(random_ids) < images_to_pull:\n",
    "        rnd_id = random.randint(0,20)\n",
    "        if rnd_id not in random_ids: \n",
    "            random_ids.append(rnd_id)\n",
    "    \n",
    "    image_set = []\n",
    "    for img_id in random_ids:\n",
    "        img = Image.open(r'imagenet_labels_concept_{}_image_{}.png'.format(concept_id, img_id))\n",
    "        image_set.append(img)\n",
    "    \n",
    "    os.chdir(old_path)\n",
    "    \n",
    "    return image_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42130022",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn\n",
    "import statistics\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7fd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring methods\n",
    "mode_list = ['topk-sq-mean', 'reg', 'mean', 'median', 'sq-mean']\n",
    "\n",
    "# remove outliers from image rankings\n",
    "def rm_outliers(ranks, rm_low_outliers, rm_high_outliers):\n",
    "    for label_id in ranks:\n",
    "        rank_arr = np.array(ranks[label_id])\n",
    "        q1 = np.quantile(rank_arr, 0.25)\n",
    "        q3 = np.quantile(rank_arr, 0.75)\n",
    "        iqr = q3-q1\n",
    "        \n",
    "        new_ranks = []\n",
    "        for pos in rank_arr:\n",
    "            if rm_low_outliers == True and pos < q1 - (iqr * 1.5):\n",
    "                continue\n",
    "            if rm_high_outliers == True and pos > q3 + (iqr * 1.5):\n",
    "                continue\n",
    "            else:\n",
    "                new_ranks.append(pos)\n",
    "        ranks[label_id] = new_ranks\n",
    "    return ranks\n",
    "\n",
    "# mean of top-k values squared\n",
    "def topk_sq_mean(ranks, k = 5):\n",
    "    top_vals = []\n",
    "    for label_id in ranks:\n",
    "        sq_sum = 0\n",
    "        for i in range(k):\n",
    "            sq_sum += (ranks[label_id][i] ** 2)\n",
    "        top_vals.append((sq_sum / k, label_id))\n",
    "    top_vals.sort()\n",
    "    return top_vals\n",
    "\n",
    "# regression + prediction\n",
    "def reg(ranks, quartile = 0.25):\n",
    "    top_vals = []\n",
    "    X_vals = [i for i in range(len(ranks[0]))]\n",
    "    p = quartile * float(len(ranks[0]))\n",
    "    \n",
    "    for label_id in ranks:\n",
    "        regr = LinearRegression()\n",
    "        regr.fit([X_vals], [ranks[label_id]])\n",
    "        pred = regr.predict(np.array([p for _ in range(len(ranks[0]))]).reshape((-1,len(ranks[0]))))[0][0]\n",
    "        top_vals.append((pred**3,label_id))\n",
    "    top_vals.sort()\n",
    "    return top_vals\n",
    "\n",
    "def mean(ranks):\n",
    "    top_vals = []\n",
    "    for label_id in ranks:\n",
    "        top_vals.append((sum(ranks[label_id])/len(ranks[label_id]), label_id))\n",
    "    top_vals.sort()\n",
    "    return top_vals\n",
    "\n",
    "def median(ranks):\n",
    "    top_vals = []\n",
    "    for label_id in ranks:\n",
    "        top_vals.append((stats.median(ranks[label_id]), label_id))\n",
    "    top_vals.sort()\n",
    "    return top_vals\n",
    "\n",
    "# mean of squared values\n",
    "def sq_mean(ranks):\n",
    "    top_vals = []\n",
    "    for label_id in ranks:\n",
    "        top_vals.append((sum([val**2 for val in ranks[label_id]])/len(ranks[label_id]), label_id))\n",
    "    top_vals.sort()\n",
    "    return top_vals\n",
    "    \n",
    "# get score of label\n",
    "def get_score(ranks, mode = 'topk-sq-mean', hyp_param = None, rm_low_outliers = False, rm_high_outliers = False):\n",
    "    if mode not in mode_list:\n",
    "        raise Exception(\"Invalid score mode '{}'\",format(mode))\n",
    "    \n",
    "    if rm_low_outliers == True or rm_high_outliers == True:\n",
    "        ranks = rm_outliers(ranks, rm_low_outliers, rm_high_outliers)\n",
    "    \n",
    "    if mode == 'topk-sq-mean':\n",
    "        return topk_sq_mean(ranks, hyp_param)\n",
    "    if mode == 'reg':\n",
    "        return reg(ranks, hyp_param)\n",
    "    if mode == 'mean':\n",
    "        return mean(ranks)\n",
    "    if mode == 'median':\n",
    "        return median(ranks)\n",
    "    if mode == 'sq-mean':\n",
    "        return sq_mean(ranks)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30155894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# for debuging purposes\n",
    "\n",
    "import sys\n",
    "del sys.modules['utils']\n",
    "del utils\n",
    "import utils\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron to check + generative label\n",
    "comp_words = {791:'checker', 880:'stripes', 844:'dotted backgrounds', \n",
    "              774:'bike', 658:'household spaces', 776:'pantry or store display', \n",
    "              188:'spider webs', 162:'purple-themed designs', 513:'polka dot patterns', \n",
    "              121:'dotted', 381:'dotted surfaces', 357:'polka dot patterns', \n",
    "              516:'striped clothing', 414:'knitting or crochet', 426:'corridor', \n",
    "              148:'dotted', 59:'spiral-themed elements', 772:'leaf', \n",
    "              945:'corridor', 277:'kitchens'}\n",
    "\n",
    "# filter out vague words\n",
    "for neuron_id in comp_words:\n",
    "    comp_words[neuron_id] = filter_word(comp_words[neuron_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4c920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(home_dir)\n",
    "os.chdir('CLIP-dissect')\n",
    "\n",
    "# del image_set\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Read labels and get D_probe\n",
    "with open(concept_set, 'r') as f:\n",
    "        words = f.read().split('\\n')\n",
    "pil_data = data_utils.get_data(d_probe)\n",
    "d_probe_len = len(pil_data)\n",
    "\n",
    "# Get directory of new saved activations\n",
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                              target_layer = target_layer, d_probe = d_probe,\n",
    "                              concept_set = concept_set, pool_mode=pool_mode,\n",
    "                              save_dir = save_dir, newSet = True)\n",
    "new_target_save_name, new_clip_save_name, text_save_name = save_names\n",
    "\n",
    "# Ensure all previous files are deleted\n",
    "location = location = \"\"\n",
    "if os.path.exists(new_target_save_name):\n",
    "    target_path = os.path.join(location, new_target_save_name) \n",
    "    os.remove(target_path)\n",
    "if os.path.exists(new_clip_save_name):\n",
    "    clip_path = os.path.join(location, new_clip_save_name)\n",
    "    os.remove(clip_path)\n",
    "if os.path.exists(new_text_save_name):\n",
    "    text_path = os.path.join(location, new_text_save_name)\n",
    "    os.remove(text_path)\n",
    "print('Removed files')\n",
    "\n",
    "# Neurons to check\n",
    "neurons_to_check = [i for i in comp_words]\n",
    "\n",
    "# Block configuration = (# labels to collect, #image per label, (#scoring model, hyperparameter if required))\n",
    "it_settings = [(15, 10, ('topk-sq-mean', 5))]\n",
    "# it_settings = [(15, 10, ('topk-sq-mean', 5)), (10, 8, ('topk-sq-mean', 5)), (3, 15, ('topk-sq-mean', 3))]\n",
    "\n",
    "# Main code\n",
    "for list_id, orig_id in enumerate(neurons_to_check):\n",
    "    \n",
    "    # Add the generative word to the concept set\n",
    "    words.append(comp_words[orig_id])\n",
    "    \n",
    "    save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                              target_layer = target_layer, d_probe = d_probe,\n",
    "                              concept_set = concept_set, pool_mode=pool_mode,\n",
    "                              save_dir = save_dir)\n",
    "    target_save_name, clip_save_name, text_save_name = save_names\n",
    "    \n",
    "    # Make sure saved text files from previous runs are deleted\n",
    "    if os.path.exists(text_save_name):\n",
    "        location = location = \"\"\n",
    "        text_path = os.path.join(location, text_save_name)\n",
    "        os.remove(text_path)\n",
    "        print('Removed files')\n",
    "\n",
    "    # Save new concept set\n",
    "    clip_model, clip_preprocess = clip.load(clip_name, device=device)\n",
    "    text = clip.tokenize([\"{}\".format(word) for word in words]).to(device)\n",
    "    utils.save_clip_text_features(clip_model, text, text_save_name, batch_size)\n",
    "\n",
    "    # Get similarities and target_feats\n",
    "    similarities, orig_target_feats = utils.get_similarity_from_activations(target_save_name, clip_save_name,\n",
    "                                                             text_save_name, similarity_fn, device=device)\n",
    "    \n",
    "    # Sort labels by similarity highest -> lowest\n",
    "    _, ids = torch.topk(similarities[orig_id], k=len(similarities[orig_id]), largest=True)\n",
    "    \n",
    "    # Initialize starting concepts\n",
    "    word_list = []\n",
    "    for label_id in range(it_settings[0][0]):\n",
    "        print('id:{}'.format(int(ids[label_id])))\n",
    "        word_list.append(words[int(ids[label_id])])\n",
    "        \n",
    "    # add generative label if generative label CLIP-dissect rank > # labels to collect in first block\n",
    "    if comp_words[orig_id] not in word_list:\n",
    "        for lb_id in range(it_settings[0][0], len(ids)):\n",
    "            if words[int(ids[lb_id])] == comp_words[orig_id]:\n",
    "                print('Word found at position {}'.format(lb_id))\n",
    "                word_list.append(words[int(ids[lb_id])])\n",
    "                break\n",
    "    \n",
    "    print(\"Neuron {}\".format(orig_id))\n",
    "    \n",
    "    best_label = \"\"\n",
    "\n",
    "    gathered = False\n",
    "    \n",
    "    # CLIP-dissect's best label\n",
    "    print('best: {}'.format(word_list[0]))\n",
    "\n",
    "    # For each block\n",
    "    for it_num, it in enumerate(it_settings):\n",
    "\n",
    "        # Block iteration\n",
    "        print(\"Iteration: {}\".format(it_num))\n",
    "        \n",
    "        # Print where generative label was found\n",
    "        if comp_words[orig_id] in word_list:\n",
    "            if it_num == 0: \n",
    "                gathered = True\n",
    "            print('Word found at position {}'.format(word_list.index(comp_words[orig_id])))\n",
    "        else: # Rank > number labels to gather for the block\n",
    "            print('Not in list')\n",
    "            break\n",
    "        \n",
    "        # Get block settings\n",
    "        labels_to_check, num_images_per_prompt, mode_description = it\n",
    "        mode, hyp_param = mode_description\n",
    "        \n",
    "        # Account for added generative label (if necessary)\n",
    "        labels_to_check = max(labels_to_check, len(word_list))\n",
    "        \n",
    "        print(labels_to_check, num_images_per_prompt)\n",
    "        \n",
    "        add_im = {}\n",
    "        add_im_id = {}\n",
    "        labels = {}\n",
    "        \n",
    "        print('Gathering images...', end = \"\")\n",
    "\n",
    "        # Generate images for each label\n",
    "        for label_id in range(labels_to_check):\n",
    "            pred_label = word_list[label_id]\n",
    "            labels[label_id] = pred_label # maps label_id to label\n",
    "\n",
    "            add_im_id[label_id] = [] # initialize image list\n",
    "\n",
    "            # Generate images\n",
    "            image_set = pipe(pred_label, generator = generator, num_images_per_prompt = num_images_per_prompt, num_inference_steps=15)\n",
    "\n",
    "            # Use this if using pre-generated images\n",
    "            # image_set = get_images(pred_label, num_images_per_prompt, old_path = os.getcwd(), home_dir = home_dir, new_path = '/expanse/lustre/scratch/nbai/temp_project/generated_images')\n",
    "\n",
    "            for i in range(num_images_per_prompt):\n",
    "                # Use this if using pre-generated images\n",
    "                #image = image_set[i]\n",
    "\n",
    "                # Rescale image\n",
    "                image = image_set.images[i]\n",
    "                image = image.resize([32,32])\n",
    "\n",
    "                new_idx = len(add_im)\n",
    "                add_im[new_idx] = image # Add image to list\n",
    "                add_im_id[label_id].append(new_idx) # map new image indices to corresponding label_id\n",
    "        print('Done')\n",
    "        del image_set\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # save the new concept set and d_probe\n",
    "        # reuse cifar100 class to store information (because i'm lazy lol)\n",
    "        utils.save_new_activations(clip_name = clip_name, target_name = target_name, target_layers = [target_layer],\n",
    "                          d_probe = 'cifar100_train', new_images = add_im,\n",
    "                          concept_set = concept_set, wordList = word_list, batch_size = batch_size,\n",
    "                          device = device, pool_mode=pool_mode, save_dir = save_dir)\n",
    "\n",
    "        # Get new similarity and target_feats\n",
    "        save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                    target_layer = target_layer, d_probe = 'cifar100_train',\n",
    "                                    concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                    save_dir = save_dir, newSet = True)\n",
    "\n",
    "        new_target_save_name, new_clip_save_name, new_text_save_name = save_names   \n",
    "\n",
    "        similarity, target_feats = utils.get_similarity_from_activations(new_target_save_name, new_clip_save_name,\n",
    "                                                                 new_text_save_name, similarity_fn, k=len(add_im), device=device)\n",
    "        \n",
    "        # Sort images based on activation\n",
    "        top_vals, top_ids = torch.sort(target_feats, dim=0, descending = True)\n",
    "        top_image_id = top_ids[:,orig_id]\n",
    "\n",
    "        # Ranks: label_id -> (indicies of corresponding images in sorted target_feats)\n",
    "        ranks = {label_id:[] for label_id in range(labels_to_check)}\n",
    "\n",
    "        # Insert indices of image activations into ranks\n",
    "        for label_id in range(labels_to_check):\n",
    "            for i, img_id in enumerate(top_image_id):\n",
    "                if img_id in add_im_id[label_id]:\n",
    "                    ranks[label_id].append(i)\n",
    "            ranks[label_id].sort()\n",
    "        \n",
    "        # Reset word_list\n",
    "        word_list = []\n",
    "        top_avg = []\n",
    "        \n",
    "        # Score labels based on ranks of corresponding generated images\n",
    "        if mode != 'soft-wpmi':\n",
    "            top_avg = get_score(ranks, mode, hyp_param, rm_high_outliers = True)\n",
    "        else:\n",
    "            new_val, new_id = torch.topk(similarity[orig_id], k=labels_to_check, largest=True)\n",
    "            print(new_id.shape)\n",
    "            for i in range(len(new_val)):\n",
    "                top_avg.append((int(new_val[i]), int(new_id[i])))\n",
    "            \n",
    "        if it_num < len(it_settings) - 1: # Generate concept set for next block iteration\n",
    "            for next_word in range(it_settings[it_num + 1][0]):\n",
    "                word_list.append(labels[top_avg[next_word][1]])\n",
    "            print(\"new list size: {}\".format(len(word_list)))\n",
    "        else: # Record best label\n",
    "            best_label = labels[top_avg[0][1]]\n",
    "            \n",
    "        # Get position of generative label\n",
    "        in_list = False\n",
    "        for i in range(len(top_avg)):\n",
    "            if labels[top_avg[i][1]] == comp_words[orig_id]:\n",
    "                print(\"Generative Label found at position: {}\".format(i))\n",
    "                in_list = True\n",
    "                break\n",
    "        \n",
    "        # For debugging purposes\n",
    "        # if in_list == False:\n",
    "        #     print(\"Not found in top {}\".format(it_settings[0][0]))\n",
    "        \n",
    "        #for i in range(3):\n",
    "        #   print('Rank {} ({}): {}'.format(i, labels[top_avg[i][1]], ranks[top_avg[i][1]]))\n",
    "        \n",
    "        # Remove files for next iteration\n",
    "        location = \"\"\n",
    "        target_path = os.path.join(location, new_target_save_name)  \n",
    "        clip_path = os.path.join(location, new_clip_save_name)\n",
    "        text_path = os.path.join(location, new_text_save_name)\n",
    "        os.remove(target_path)\n",
    "        os.remove(clip_path)\n",
    "        os.remove(text_path)\n",
    "    \n",
    "    # Print results\n",
    "    if gathered == True:\n",
    "        print('------------------------------\\n')\n",
    "        print('Neuron {}:'.format(orig_id))\n",
    "        print('CLIP Label: {}'.format(words[int(ids[0])]))\n",
    "        print('New Label: {}'.format(best_label))\n",
    "        print('\\n------------------------------')\n",
    "\n",
    "    # Remove added generative label\n",
    "    words = words[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
