{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron to check + generative label\n",
    "# This is the part BLIP feeds into experiment 3\n",
    "comp_words = {1:['tench','goldfish', 'ax' 'great white shark', 'yellow', 'natures beauty']}\n",
    "\n",
    "# filter out vague words\n",
    "for neuron_id in comp_words:\n",
    "    for i in range(len(comp_words[neuron_id])):\n",
    "        comp_words[neuron_id][i] = filter_word(comp_words[neuron_id][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_dir)\n",
    "os.chdir('CLIP-dissect')\n",
    "\n",
    "# del image_set\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get D_probe\n",
    "pil_data = data_utils.get_data(d_probe)\n",
    "d_probe_len = len(pil_data)\n",
    "\n",
    "# Define concept set\n",
    "words = []\n",
    "\n",
    "# Get directory of new saved activations\n",
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                              target_layer = target_layer, d_probe = d_probe,\n",
    "                              concept_set = concept_set, pool_mode=pool_mode,\n",
    "                              save_dir = save_dir, newSet = True)\n",
    "new_target_save_name, new_clip_save_name, new_text_save_name = save_names\n",
    "\n",
    "# Ensure all previous files are deleted\n",
    "location = location = \"\"\n",
    "if os.path.exists(new_target_save_name):\n",
    "    target_path = os.path.join(location, new_target_save_name) \n",
    "    os.remove(target_path)\n",
    "if os.path.exists(new_clip_save_name):\n",
    "    clip_path = os.path.join(location, new_clip_save_name)\n",
    "    os.remove(clip_path)\n",
    "if os.path.exists(new_text_save_name):\n",
    "    text_path = os.path.join(location, new_text_save_name)\n",
    "    os.remove(text_path)\n",
    "print('Removed files')\n",
    "\n",
    "# Neurons to check\n",
    "neurons_to_check = [i for i in comp_words]\n",
    "\n",
    "# Block configuration = (# labels to collect, #image per label, (#scoring model, hyperparameter if required))\n",
    "it_settings = [(15, 10, ('topk-sq-mean', 5))]\n",
    "# it_settings = [(15, 10, ('topk-sq-mean', 5)), (10, 8, ('topk-sq-mean', 5)), (3, 15, ('topk-sq-mean', 3))]\n",
    "\n",
    "# Main code\n",
    "for list_id, orig_id in enumerate(neurons_to_check):\n",
    "    \n",
    "    # Add the generative word to the concept set\n",
    "    words = comp_words[orig_id]\n",
    "    \n",
    "    save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                              target_layer = target_layer, d_probe = d_probe,\n",
    "                              concept_set = concept_set, pool_mode=pool_mode,\n",
    "                              save_dir = save_dir)\n",
    "    target_save_name, clip_save_name, text_save_name = save_names\n",
    "    \n",
    "    # Make sure saved text files from previous runs are deleted\n",
    "    if os.path.exists(text_save_name):\n",
    "        location = location = \"\"\n",
    "        text_path = os.path.join(location, text_save_name)\n",
    "        os.remove(text_path)\n",
    "        print('Removed files')\n",
    "\n",
    "    # Save new concept set\n",
    "    clip_model, clip_preprocess = clip.load(clip_name, device=device)\n",
    "    text = clip.tokenize([\"{}\".format(word) for word in words]).to(device)\n",
    "    utils.save_clip_text_features(clip_model, text, text_save_name, batch_size)\n",
    "\n",
    "    # Get similarities and target_feats\n",
    "    similarities, orig_target_feats = utils.get_similarity_from_activations(target_save_name, clip_save_name,\n",
    "                                                             text_save_name, similarity_fn, device=device)\n",
    "    \n",
    "    # Sort labels by similarity highest -> lowest\n",
    "    _, ids = torch.sort(similarities[orig_id], descending = True)\n",
    "    \n",
    "    # Initialize starting concepts\n",
    "    word_list = []\n",
    "    for label_id in range(min(it_settings[0][0], len(ids))):\n",
    "        word_list.append(words[int(ids[label_id])])\n",
    "    \n",
    "    print(\"Neuron {}\".format(orig_id))\n",
    "    \n",
    "    best_label = \"\"\n",
    "\n",
    "    # For each block\n",
    "    for it_num, it in enumerate(it_settings):\n",
    "\n",
    "        # Block iteration\n",
    "        print(\"Iteration: {}\".format(it_num))\n",
    "        \n",
    "        # Get block settings\n",
    "        labels_to_check, num_images_per_prompt, mode_description = it\n",
    "        mode, hyp_param = mode_description\n",
    "        \n",
    "        # Account for added generative label (if necessary)\n",
    "        labels_to_check = min(labels_to_check, len(word_list))\n",
    "        \n",
    "        print(labels_to_check, num_images_per_prompt)\n",
    "        \n",
    "        add_im = {}\n",
    "        add_im_id = {}\n",
    "        labels = {}\n",
    "        \n",
    "        print('Gathering images...', end = \"\")\n",
    "\n",
    "        # Generate images for each label\n",
    "        for label_id in range(labels_to_check):\n",
    "            pred_label = word_list[label_id]\n",
    "            labels[label_id] = pred_label # maps label_id to label\n",
    "\n",
    "            add_im_id[label_id] = [] # initialize image list\n",
    "\n",
    "            # Generate images\n",
    "            image_set = pipe(pred_label, generator = generator, num_images_per_prompt = num_images_per_prompt, num_inference_steps=15)\n",
    "\n",
    "            # Use this if using pre-generated images\n",
    "            # image_set = get_images(pred_label, num_images_per_prompt, old_path = os.getcwd(), home_dir = home_dir, new_path = '/expanse/lustre/scratch/nbai/temp_project/generated_images')\n",
    "\n",
    "            for i in range(num_images_per_prompt):\n",
    "                # Use this if using pre-generated images\n",
    "                #image = image_set[i]\n",
    "\n",
    "                # Rescale image\n",
    "                image = image_set.images[i]\n",
    "                image = image.resize([32,32])\n",
    "\n",
    "                new_idx = len(add_im)\n",
    "                add_im[new_idx] = image # Add image to list\n",
    "                add_im_id[label_id].append(new_idx) # map new image indices to corresponding label_id\n",
    "        print('Done')\n",
    "        del image_set\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # save the new concept set and d_probe\n",
    "        # reuse cifar100 class to store information (because i'm lazy lol)\n",
    "        utils.save_new_activations(clip_name = clip_name, target_name = target_name, target_layers = [target_layer],\n",
    "                          d_probe = 'cifar100_train', new_images = add_im,\n",
    "                          concept_set = concept_set, wordList = word_list, batch_size = batch_size,\n",
    "                          device = device, pool_mode=pool_mode, save_dir = save_dir)\n",
    "\n",
    "        # Get new similarity and target_feats\n",
    "        save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                    target_layer = target_layer, d_probe = 'cifar100_train',\n",
    "                                    concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                    save_dir = save_dir, newSet = True)\n",
    "\n",
    "        new_target_save_name, new_clip_save_name, new_text_save_name = save_names   \n",
    "\n",
    "        similarity, target_feats = utils.get_similarity_from_activations(new_target_save_name, new_clip_save_name,\n",
    "                                                                 new_text_save_name, similarity_fn, k=len(add_im), device=device)\n",
    "        \n",
    "        # Sort images based on activation\n",
    "        top_vals, top_ids = torch.sort(target_feats, dim=0, descending = True)\n",
    "        top_image_id = top_ids[:,orig_id]\n",
    "\n",
    "        # Ranks: label_id -> (indicies of corresponding images in sorted target_feats)\n",
    "        ranks = {label_id:[] for label_id in range(labels_to_check)}\n",
    "\n",
    "        # Insert indices of image activations into ranks\n",
    "        for label_id in range(labels_to_check):\n",
    "            for i, img_id in enumerate(top_image_id):\n",
    "                if img_id in add_im_id[label_id]:\n",
    "                    ranks[label_id].append(i)\n",
    "            ranks[label_id].sort()\n",
    "        \n",
    "        # Reset word_list\n",
    "        word_list = []\n",
    "        top_avg = []\n",
    "        \n",
    "        # Score labels based on ranks of corresponding generated images\n",
    "        if mode != 'soft-wpmi':\n",
    "            top_avg = get_score(ranks, mode, hyp_param, rm_high_outliers = True)\n",
    "        else:\n",
    "            new_val, new_id = torch.topk(similarity[orig_id], k=labels_to_check, largest=True)\n",
    "            print(new_id.shape)\n",
    "            for i in range(len(new_val)):\n",
    "                top_avg.append((int(new_val[i]), int(new_id[i])))\n",
    "            \n",
    "        if it_num < len(it_settings) - 1: # Generate concept set for next block iteration\n",
    "            for next_word in range(it_settings[it_num + 1][0]):\n",
    "                word_list.append(labels[top_avg[next_word][1]])\n",
    "            print(\"new list size: {}\".format(len(word_list)))\n",
    "        else: # Record best label\n",
    "            best_label = labels[top_avg[0][1]]\n",
    "            \n",
    "        # Get position of generative label\n",
    "        in_list = False\n",
    "        for i in range(len(top_avg)):\n",
    "            if labels[top_avg[i][1]] == comp_words[orig_id]:\n",
    "                print(\"Generative Label found at position: {}\".format(i))\n",
    "                in_list = True\n",
    "                break\n",
    "        \n",
    "        # For debugging purposes\n",
    "        # if in_list == False:\n",
    "        #     print(\"Not found in top {}\".format(it_settings[0][0]))\n",
    "        \n",
    "        #for i in range(3):\n",
    "        #   print('Rank {} ({}): {}'.format(i, labels[top_avg[i][1]], ranks[top_avg[i][1]]))\n",
    "        \n",
    "        # Remove files for next iteration\n",
    "        location = \"\"\n",
    "        target_path = os.path.join(location, new_target_save_name)  \n",
    "        clip_path = os.path.join(location, new_clip_save_name)\n",
    "        text_path = os.path.join(location, new_text_save_name)\n",
    "        os.remove(target_path)\n",
    "        os.remove(clip_path)\n",
    "        os.remove(text_path)\n",
    "    \n",
    "    # Print results\n",
    "    print('------------------------------\\n')\n",
    "    print('Neuron {}:'.format(orig_id))\n",
    "    print('New Label: {}'.format(best_label))\n",
    "    print('\\n------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
